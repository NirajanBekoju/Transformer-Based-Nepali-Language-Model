{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea56036d",
   "metadata": {},
   "source": [
    "# Import Torch functions and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8527adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import regex as re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from model import TransformerModel\n",
    "from utils import preProcessText, getTokenizer,try_gpu , word_piece_decoder, word_piece_encoder\n",
    "from config import getConfig\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64201d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emsize': 300, 'd_hid': 1024, 'nlayers': 6, 'nhead': 6, 'dropout': 0.2, 'bptt': 64}\n",
      "{'logs': 'tensorboard_logs', 'epochs': 25}\n"
     ]
    }
   ],
   "source": [
    "# model_config, app_config = getConfig(small = True)\n",
    "model_config, app_config = getConfig()\n",
    "print(model_config)\n",
    "print(app_config)\n",
    "\n",
    "bptt=model_config[\"bptt\"]\n",
    "device = try_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba983f7",
   "metadata": {},
   "source": [
    "# Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740ae401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18adf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  : data/preprocessed_morph.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 'data/preprocessed_morph.txt'\n",
    "if not os.path.exists(file_path):\n",
    "    print(\"Run morpheme_datagen notebook\")\n",
    "else:\n",
    "    print(f\"Reading file  : {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = preProcessText(text,tokenizer_type = 'morpheme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59c6611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'बर्दिबास * नगरपालिका को * तेस्रो * नगर * परिषदबाट * पारित * आव २०७३ * । * ७४ * को * संशोधित * र * २०७४ * । * ७५ * को * प्रस्तावित * नीति * ? * कार्यक्रम * तथा * बजेट\\nअार्थिक * वर्ष * २०७५७६ * काे * नदिजन्य * पदार्थ काे * उत्खनन् * गरी * बिक्रि * वितरण * तथा * अान्तरिक * निकासी * गर्ने * कार्य काे * बाेलपत्र * सम्बन्धी * सुचना\\nसक्ष ार * सप्तरी * अभियानमा * सप्तरीबासी * सम्पूर्ण * सरोकारवालाहरु को * सहयोग * र * सहभागिता का ो * लागि * अनुराोध * छ * । * सामुदायिक * अध्ययन * केन्द्र हरूको * नविकरण * सम्बन्धमा * । * \\nकाठमाडौं * ? * १२ * कातिक * । * राष्ट्रपति * विद्यादेवी * भण्डारी * मित्रराष्ट्र * कतारको * चार * दिवसीय * औपचारिक * भ्रमणमा * आज * त्यसतर्फ * प्रस्थान * गरेकी * छन् * । * राष्ट्रपति * विद्या देवी * भण्डारी * कतारका * अमिर * शेख * ह मा द * बीन * खालिदा * अल * थानीको * मैत्री पूर्ण * निमन्त्रणामा * चार * दिवसीय * औपचारिक\\nकाठमाडौँ * ? * २६ * कात्तिक * । * सरकारले * सङ्घ * ? * प्रदेश * र * स्थानीय * तहमा * कर्मचारी * समायोजन * गर्नका * लागि * कर्मचारी * समायोजन * अध्यादेश २०७५ * ल्याउने * तयारी * गरेको * छ * । * सरकारले * यसअघि * ल्याएको\\nकाठमाडौं * ? * २६ * कातिक * । * महानायक * राजेश * हमाल * अहिले * चलचित्र * क्षेत्रमा * पातलिए * पनि * उनको * सिने * जगतमा * नामै * काफी * छ * । * कुनै * समय * बलिउड * सुपरस्टार * अमिताभ * वच्चन सँग\\nकाठमाडौं * ? * २६ * कातिक * । * यमनको * प्रमुख * शहर * होडेडामा * सरकार * समर्थक * र * विद्रोही बीच * भएको * पछिल्लो * युद्ध मा * एक * सय * ४९ * जनाको * मृत्यु * भएको * चिकित्सक * र * सैनिक * स्रोतले\\nकाठमाडौं * ? * २६ * कातिक * । * निजी * क्षेत्र बाट * निर्माण * भएको * पहिलो * चलचित्र * माइतीघर का * छाँयाकार * गेहेन्द्र प्रसाद * धिमालको * ७२\\nनेपाल * कम्युनिष्ट * पार्टी * नेकपाको * एकीकरण * प्रक्रिया * जारी * छ * । * तर * ? * ३ * जेठ * २०७५ * मा * पार्टी * एकताको * घोषणा * हुदै * गर्दा * जुन * कार्यतालिका * बनाइएको * थियो * । * त्यो\\nसुर्खेत * ? * १ * कात्तिक * । * गत * शुक्रबार * आठबीस * नगरपालिका१ * डाव * दैलेखका * कर्णबहादुर * रावत * र * उनकी * श्रीमतीलाई * चिया * चाउचाउ * नास्ता * खुवाउन * भ्याइ * नभ्याइ * थियो * । * खासै * यसअघि * दुईचार * स्थानीय * ग्राहक * आउने * त्यस * चिया * पसलमा * उक्त * दिनको * भीडले * भने * रावत * दम्पती * निकै * दङ्ग * थिए * । * त्यहाँ * कर्णाली * प्रदेश * सरकार * ? * आन्तरिक * तथा * विदेशी * पाहुना * पुगेका * थिए * । * आजभोलि * रावत झैँ\\nकाठमाडौं * ? * २२ * कात्तिक * । * सशस्त्र * प्रहरी * बलको * मुख्यालय मा * मंगलबार * कुकुर * तिहारका * दिन * देउसीभै ली * कार्यक्रम * गरिएको * थियो * । * सशस्त्र * प्रहरी * परिवार * महिला * संघको * ब्यानर मा * गरिएको * उक्त * दिनको * देउसी * भैली * कार्यक्रम * रमाइलोका * लागि * र * स्वेच्छिक * रुपमा * दान * दिने * उद्देश्य ले * गरिएको * नभई * जबर्जस्ती * असुलीका * लागि * गरिएको * सन्देश * गएको\\nकाठमाडौं * ? * २६ * कातिक * । * नेपाल * स्टक * एक्सचेञ्ज ले * कारोवार * रकम * तलमाथि * परेको * भन्दै * आएको * गुनासो * हल्ला * मात्रै * भएको * जनाएको * छ * । * कारोवार * रकम लगायतका * विषयमा * अन्योलता * बढेपछि * केही * लगानीकर्ता ले * एउटा * दलालको * देखि रहेको * मूल्य * र * अर्को * दलालमा * देखि रहेको\\nकाठमाडौं * ? * २२ * कात्तिक * । * सशस्त्र * प्रहरी * बलको * मुख्यालय मा * मंगलबार * कुकुर * तिहारका * दिन * देउसीभै ली * कार्यक्रम * गरिएको * थियो * । * सशस्त्र * प्रहरी * परिवार * महिला * संघको * ब्यानर मा * गरिएको * उक्त * दिनको * देउसी * भैली * कार्यक्रम * रमाइलोका * लागि * र * स्वेच्छिक * रुपमा * दान * दिने * उद्देश्य ले * गरिएको * नभई * जबर्जस्ती * असुलीका * लागि * गरिएको * सन्देश * गएको * छ * । * पदको * आडमा * रकम * उठाउन * गरिएको * थियो * भन्ने * कुरा\\nपेरिस * ? * २५ * कार्तिक * । * पहिलो * विश्वयुद्ध * समाप्तिको * एक * सय * वर्ष * अवसर * पारेर * फ्रान्सको * पेरिसमा * विशेष * कार्यक्रम * आयोजना * गरिएको * छ * । * प्रथम * विश्वयुद्ध * अन्त्य * भएको * सम्झौतामा * हस्ताक्षर * गरिएको * एकसय * वर्ष * पुगेको * सम्झना मा * पेरिसमा * आयोजित * एउटा * समारोहमा * विश्व का\\nहङकङ * चीनले * संसारलाई * चकित * तुल्याउने * गरी * छोटो * समयमै * विश्वकै * लामो * समुन्द्री * पुलको * निर्माण * कार्य * सम्पन्न * गरेको * छ * । * हङकङमकाउचुहाई * जोड्न * ७ * किलोमिटर * सामुद्रिक * सुरङसहित * ५५ * किलोमिटर * लामो * सामुद्रिक * पुल * चीनले * निर्माण * गरेर * उद्घाटन * गरेको * हो * । * तस्बिरहरु * ऐजेन्सी * चिनियाँ * सहर * जुहाईको * हुँदै * मकाउ * जोड्ने\\nकाठमाडौं * ? * १३ * कात्तिक * । * नेपाल * एयर * होस्टेस * एकाडमीद्धारा * सञ्चालित * एयर * होस्टेस * तालिम * लिएका * विद्यार्थी * दीक्षित * भएका * छन् * । * मकवानपुर मा * एक * कार्यक्रम को * विच * मंगलवार * १८ * जना * एयरहोस्टेस * दीक्षित * भए * । * तालिम * लिएका * युवायुवती हरुलाई * उक्त * एयरहोस्टेस * एकाडमीका * शिक्षकहरु * नितामनि\\nदमौली * । * तनँहुको * पर्यटकीय * नगरी * बन्दीपुर मा * कृत्रिम * ताल * बनाइने * भएको * छ * । * पहाडकी * रानी * नामले * परिचित * बन्दीपुर को * पर्यटन * प्रवद्र्धन * गर्न * मानवनिर्मित * ताल * बनाउन * लागिएको * हो * । * सोमबार * प्रसिद्ध * अर्थशास्त्री * कार्लो * को टेरे ली लाई * नयाँ * सरकारको * नेतृत्व * गर्न * आग्रह * गर्दै * तत्काल * यहाँको * मन्त्रीमण्डल * विस्तार * गर्ने * जनादेश * प्रदान * गरेका * छन् * राष्ट्रपति को * कार्यालयबाट * जारी * एक * विज्ञप्ति मा * जनाइएको * छ * । * प्रधानमन्त्री मा * आफ्नो * नाम * प्रस्ताव ित * भएपछि * कोटेरेलीले * देशवासी लाई * सम्बोधन *'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b02d3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123563"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b4a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_first = text.split('\\n')[:100_000]\n",
    "test_iter = text.split('\\n')[100_000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2781400f",
   "metadata": {},
   "source": [
    "# Run Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006d0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "\n",
    "# tokenizer = get_tokenizer(None)\n",
    "\n",
    "# vocab = build_vocab_from_iterator(\n",
    "#     map(tokenizer, train_iter_first), specials=['<unk>'],max_tokens = 30000)\n",
    "# vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "\n",
    "# # Save for first time\n",
    "# with open('transformer_vocab_morpheme.pickle','wb') as f:\n",
    "#     pickle.dump(vocab,f)\n",
    "\n",
    "tokenizer,vocab = getTokenizer(tokenizer_type = 'morpheme')\n",
    "\n",
    "# with open('tokenizers/transformer_vocab_morpheme.pickle','rb') as f:\n",
    "#     vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8092b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c622c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bb6300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " '+',\n",
       " '++',\n",
       " '<unk>',\n",
       " '?',\n",
       " 'ँ',\n",
       " 'ँदा',\n",
       " 'ँदै',\n",
       " 'ँदैछ',\n",
       " 'ँदैछन्',\n",
       " 'ँदैन',\n",
       " 'ँदैनन्',\n",
       " 'ँदो',\n",
       " 'ं',\n",
       " 'ंदा',\n",
       " 'ंदै',\n",
       " 'ंदैछ',\n",
       " 'ंदैन',\n",
       " 'ः',\n",
       " 'ः३०']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((vocab.get_stoi()))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f4391b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c810f3",
   "metadata": {},
   "source": [
    "#  some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32332624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long)\n",
    "            for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "    Args:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "    Returns:\n",
    "        Tensor of shape [N // bsz, bsz]\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "#     data = data.view(bsz, seq_len).t().contiguous()\n",
    "    data = data.view(bsz,seq_len).t()\n",
    "#     return data.to(device)\n",
    "    return data\n",
    "\n",
    "\n",
    "seq_length = bptt\n",
    "def get_batch(source: Tensor, i: int) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(seq_length, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    #target = source[i+1:i+1+seq_len]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e41fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test Split\n",
    "train_data = data_process(train_iter_first)\n",
    "test_data = data_process(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5674c13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44038548"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ca4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14037,     1,   146,     4,     1,   572,     1,   778,     1,     0,\n",
       "            1,   985,     1,  1879,  1520,     1,     2,     1,  3696,     1,\n",
       "            4,     1, 11933,     1,     5,     1,   813,     1,     2,     1,\n",
       "         1527,     1,     4,     1,  4469,     1,   366,     1,     3,     1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d40be4",
   "metadata": {},
   "source": [
    "# Working with a dummy Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda3aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Data\n",
    "\n",
    "\n",
    "text = ['आधिकारिक निर्णयको कारणले , वाणिज्य बिभागले , संयुक्त राज्य अमेरिकी समुद्री पानी निर्माताद्वारा संयुक्त राज्य']\n",
    "text = ['। * सामुदायिक * अध्ययन * केन्द्र हरूको *']\n",
    "#text = ['जनसंख्या']\n",
    "sample_data = data_process(\n",
    "    text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c88184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2,    1, 1079,    1,  290,    1,  197,  329,    1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9de8a21a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given word: । * सामुदायिक * अध्ययन * केन्द्र हरूको *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    1,  197],\n",
       "        [   1,  290,  329],\n",
       "        [1079,    1,    1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = batchify(sample_data, 3)\n",
    "print(\"Given word:\", text[0])\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd7744",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43358ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched_train_data = batchify(train_data, bptt).to(device)  # shape [seq_len, batch_size]\n",
    "# batched_test_data = batchify(test_data, bptt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "551e4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config, ntokens):\n",
    "    emsize = model_config[\"emsize\"]\n",
    "    d_hid = model_config[\"d_hid\"]\n",
    "    nlayers = model_config[\"nlayers\"]\n",
    "    nhead = model_config[\"nhead\"]\n",
    "    dropout = model_config[\"dropout\"]\n",
    "    model = TransformerModel(ntokens, emsize,nhead, d_hid, nlayers, dropout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59077853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103103488"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntokens = len(vocab)\n",
    "model = get_model(model_config, ntokens).to(device)\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee046362",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_train_data = batchify(train_data, bptt).to(device)  # shape [seq_len, batch_size]\n",
    "batched_test_data = batchify(test_data, bptt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1da52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = bptt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf7ec3",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83f7a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "softmax = nn.Softmax(dim=2)\n",
    "#softmax = nn.LogSoftmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c7cfdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bcf16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module) -> None:\n",
    "    global epoch\n",
    "    global global_step\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(batched_train_data) // bptt\n",
    "    progress_bar = tqdm(enumerate(range(0, batched_train_data.size(0) - 1, bptt)), total=num_batches, desc=f'Epoch {epoch}', ncols=80)\n",
    "    for batch_idx, i in progress_bar:\n",
    "        ### batch_idx -> (1, 2, 3, 4, ...)\n",
    "        ### i -> (0, bptt, 2*bptt, ....)\n",
    "        data, targets = get_batch(batched_train_data, i)\n",
    "        batch_size = data.size(0)\n",
    "        if batch_size != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:batch_size, :batch_size]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        ## calculate the postfix description for the progress bar\n",
    "        cur_loss = total_loss / (batch_idx + 1)\n",
    "        ppl = math.exp(cur_loss)\n",
    "        \n",
    "        progress_bar.set_postfix({\"loss\": cur_loss, \"ppl\" : ppl}, refresh=True)\n",
    "        \n",
    "        writer.add_scalar('loss/train loss', cur_loss, global_step)\n",
    "        writer.flush()\n",
    "        writer.add_scalar('ppl/train perplexity', ppl, global_step)\n",
    "        writer.flush()\n",
    "        global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb16cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(eval_data) // bptt\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(range(0, eval_data.size(0) - 1, bptt)), total=num_batches, desc=f'Validation {epoch}', ncols=80)\n",
    "        for batch_idx, i in progress_bar:\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            batch_size = data.size(0)\n",
    "            if batch_size != bptt:\n",
    "                src_mask = src_mask[:batch_size, :batch_size]\n",
    "            output = model(data, src_mask)\n",
    "            output_softmax = softmax(output)\n",
    "            output_softmax_permuted = output_softmax.permute(1, 0, 2)\n",
    "            indices = torch.argmax(output_softmax_permuted, dim=2)\n",
    "            target_indices = targets.t()\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
    "    \n",
    "    eval_loss = total_loss / (len(eval_data) - 1)\n",
    "    eval_ppl = math.exp(eval_loss)\n",
    "\n",
    "    writer.add_scalar('loss/val loss', eval_loss, global_step)\n",
    "    writer.flush()\n",
    "    writer.add_scalar('ppl/val perplexity', eval_ppl, global_step)\n",
    "    writer.flush()\n",
    "\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e875bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2)\n",
    "#softmax = nn.LogSoftmax(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d73f1d",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29881c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = 'models/best_model_mp_new.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f532766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 10752it [47:01,  3.81it/s, loss=3.6, ppl=36.6]                         \n",
      "Validation 0: 2556it [04:11, 10.18it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 24.895583496259558\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 10752it [46:20,  3.87it/s, loss=3.12, ppl=22.8]                        \n",
      "Validation 1: 2556it [04:03, 10.50it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 19.38394365305096\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 10752it [45:18,  3.95it/s, loss=2.95, ppl=19.2]                        \n",
      "Validation 2: 2556it [04:02, 10.53it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 17.18342729078689\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 10752it [45:33,  3.93it/s, loss=2.86, ppl=17.4]                        \n",
      "Validation 3: 2556it [04:01, 10.57it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 15.991305865402195\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 10752it [45:30,  3.94it/s, loss=2.79, ppl=16.3]                        \n",
      "Validation 4: 2556it [04:03, 10.51it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 15.234579721794624\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 10752it [45:09,  3.97it/s, loss=2.75, ppl=15.6]                        \n",
      "Validation 5: 2556it [04:01, 10.59it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 14.649291570803124\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 10752it [45:04,  3.97it/s, loss=2.71, ppl=15.1]                        \n",
      "Validation 6: 2556it [04:00, 10.63it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 14.271960201461951\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 10752it [44:58,  3.98it/s, loss=2.68, ppl=14.6]                        \n",
      "Validation 7: 2556it [04:00, 10.61it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 13.947761322996438\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 10752it [45:06,  3.97it/s, loss=2.66, ppl=14.3]                        \n",
      "Validation 8: 2556it [03:59, 10.66it/s]                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval perplexity : 13.707615119019952\n",
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:  69%|█████▌  | 7444/10751 [31:07<13:49,  3.99it/s, loss=2.65, ppl=14.1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(app_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(initial_epoch, epochs):\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     eval_loss \u001b[38;5;241m=\u001b[39m evaluate(model, batched_test_data)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# save the model if validation loss decreases\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, ntokens), targets)\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mF:\\LM bytepair\\.venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\LM bytepair\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over epochs. Save the model if the validation loss is the best\n",
    "# we've seen so far. Adjust the learning rate after each epoch.\n",
    "best_val_loss = float('inf')\n",
    "initial_epoch = 0\n",
    "epochs = app_config[\"epochs\"]\n",
    "global_step = 0\n",
    "best_model = None\n",
    "\n",
    "# preload the model if exists to train more epochs\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"Preloading model {best_model_path}\")\n",
    "    state = torch.load(best_model_path)\n",
    "    \n",
    "    initial_epoch = state['epoch'] + 1\n",
    "    model.load_state_dict(state['model_state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "    global_step = state['global_step']\n",
    "    best_val_loss = state['best_val_loss']\n",
    "    \n",
    "    print(initial_epoch, global_step, best_val_loss)\n",
    "\n",
    "# initializing the tensorbaord log writer\n",
    "writer = SummaryWriter(app_config[\"logs\"])\n",
    "\n",
    "\n",
    "for epoch in range(initial_epoch, epochs):\n",
    "    train(model)\n",
    "    eval_loss = evaluate(model, batched_test_data)\n",
    "\n",
    "    # save the model if validation loss decreases\n",
    "\n",
    "    if eval_loss < best_val_loss:\n",
    "        print(f\"eval perplexity : {math.exp(eval_loss)}\")\n",
    "        print(\"saving the model\")\n",
    "        best_val_loss = eval_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "        directory_path = 'models'\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(directory_path):\n",
    "            os.makedirs(directory_path)\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'global_step': global_step, \n",
    "                'best_val_loss' : best_val_loss,\n",
    "            }, os.path.join(directory_path, 'best_model_mp_new.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c57d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnsoftmax = nn.LogSoftmax(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa4c44",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e314c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading model models/best_model_mp_new.pt\n"
     ]
    }
   ],
   "source": [
    "def loadModel(best_model_path):\n",
    "    global model\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"Preloading model {best_model_path}\")\n",
    "        if torch.cuda.is_available():\n",
    "            state = torch.load(best_model_path)\n",
    "        else:\n",
    "            state = torch.load(best_model_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        return model\n",
    "    else:\n",
    "        raise Exception(\"Model Not Found\")\n",
    "        \n",
    "loaded_model = loadModel(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2c2453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = model\n",
    "def generator(model: nn.Module, gen_data: Tensor, no_words = 10):\n",
    "    model.eval()\n",
    "    temp_text = text\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    pred_text = []\n",
    "    for i in range(no_words):\n",
    "        batch_size = gen_data.size(0)\n",
    "        if batch_size != bptt:\n",
    "            src_mask_ = src_mask[:batch_size, :batch_size]\n",
    "        else:\n",
    "            src_mask_ = src_mask[:,:]\n",
    "        output_softmax = model(gen_data, src_mask_)\n",
    "        output_softmax_permuted = output_softmax.permute(1, 0, 2)\n",
    "        indices = torch.argmax(output_softmax_permuted, dim=2)\n",
    "        pred_text.append([vocab.lookup_tokens(list(index))\n",
    "                                  for index in indices][0][-1])\n",
    "        if(batch_size < 16):\n",
    "            gen_data = torch.cat((gen_data[:,:],indices.t()[-1:][:]),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "        else:\n",
    "            gen_data = torch.cat((gen_data[1:,:],indices.t()[-1:][:]),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "            \n",
    "    return pred_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nonnaive_generator(model: nn.Module, gen_data: Tensor, no_words = 5,k=50):\n",
    "    model.eval()\n",
    "    temp_text = text\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    pred_text = []\n",
    "    for i in range(no_words):\n",
    "\n",
    "        batch_size = gen_data.size(0)\n",
    "        if batch_size != bptt:\n",
    "            src_mask_ = src_mask[:batch_size, :batch_size]\n",
    "        output_softmax = model(gen_data, src_mask_)\n",
    "        output_softmax_permuted = output_softmax.permute(1, 0, 2)\n",
    "        indices = torch.topk(output_softmax_permuted,k ,dim=2).indices.squeeze(0)\n",
    "        \n",
    "        values = torch.topk(softmax(output_softmax_permuted),k ,dim=2).values\n",
    "        values = values/torch.sum(values,dim = 2,keepdims = True)\n",
    "\n",
    "        \n",
    "        ind_sampled = torch.distributions.Categorical(values.squeeze(0)).sample()\n",
    "        next_index = indices[-1][ind_sampled[-1]]\n",
    "        \n",
    "\n",
    "        pred_text.append([vocab.lookup_token(next_index)][0])\n",
    "        if(batch_size < 15):\n",
    "            gen_data = torch.cat((gen_data[:,:],next_index.unsqueeze(0).unsqueeze(0)),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "        else:\n",
    "            gen_data = torch.cat((gen_data[1:,:],next_index.unsqueeze(0).unsqueeze(0)),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "            \n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a0620cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import morfessor\n",
    "import math\n",
    "\n",
    "with open('models/morfessor_model.p','rb') as f:\n",
    "    models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8e650e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_morph(l):\n",
    "    a = []\n",
    "    for v in l:\n",
    "        t1 = '-'.join(models[0].viterbi_segment(v)[0])\n",
    "        tr = re.sub(r'[ ]+', r' ', t1)\n",
    "        tr = re.sub(r'- -', r'*', tr)\n",
    "        tr = re.sub(r'-[ ]+', r'*', tr)\n",
    "        tr = re.sub(r'[ ]+-', r'*',tr)\n",
    "        tr = re.sub(r' ', r' * ',tr)\n",
    "        tr = re.sub(r'\\*', r' * ',tr)\n",
    "        tr = re.sub(r'  ', r' ', tr)\n",
    "        tr = re.sub(r'-', r' ',tr)\n",
    "        a.append(tr)\n",
    "    return a\n",
    "\n",
    "def revert_sentence(text):\n",
    "#     tr = re.sub(r' ', r'',text)\n",
    "    tr = re.sub(r'\\*', r' ',text)\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "772a4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = ['लामो समयसम्म प्रयोग गर्न सकिन्छ ।']\n",
    "# st = ['तपाईंलाई कस्तो पुस्तकहरू मन']\n",
    "st = ['नेपालमा आधुनिक']\n",
    "st_ = convert_to_morph(st)\n",
    "st_i = data_process(st_)\n",
    "st_i = st_i.unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49d98447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['नेपालमा * आधुनिक']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4149da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = nonnaive_generator(loaded_model, st_i,no_words = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0958c4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नेपालमा आधुनिक प्रविधिको प्रयोग गर्ने गरेका छन् । सन् २०१७ देखि हालसम्म ३ खर्ब ८ अर्ब ९ करोड रुपैयाँ मात्र राजश्व असुली भइरहेको र त्यो भन्दा बढी राजश्व संकलन भइरहेको छ । तर ? यो सबै कुरा अहिले <unk> जस्तो लागेको छ । हाम्रो <unk> धेरै कुरा बुझेको छैन तर त्यो थाहा'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st[0]+ revert_sentence(''.join(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db5c9571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['*',\n",
       " 'प्रविधिको',\n",
       " '*',\n",
       " 'प्रयोग',\n",
       " '*',\n",
       " 'गर्ने',\n",
       " '*',\n",
       " 'गरेका',\n",
       " '*',\n",
       " 'छन्',\n",
       " '*',\n",
       " '।',\n",
       " '*',\n",
       " 'सन्',\n",
       " '*',\n",
       " '२०१७',\n",
       " '*',\n",
       " 'देखि',\n",
       " '*',\n",
       " 'हालसम्म',\n",
       " '*',\n",
       " '३',\n",
       " '*',\n",
       " 'खर्ब',\n",
       " '*',\n",
       " '८',\n",
       " '*',\n",
       " 'अर्ब',\n",
       " '*',\n",
       " '९',\n",
       " '*',\n",
       " 'करोड',\n",
       " '*',\n",
       " 'रुपैयाँ',\n",
       " '*',\n",
       " 'मात्र',\n",
       " '*',\n",
       " 'राजश्व',\n",
       " '*',\n",
       " 'असुली',\n",
       " '*',\n",
       " 'भइरहेको',\n",
       " '*',\n",
       " 'र',\n",
       " '*',\n",
       " 'त्यो',\n",
       " '*',\n",
       " 'भन्दा',\n",
       " '*',\n",
       " 'बढी',\n",
       " '*',\n",
       " 'राजश्व',\n",
       " '*',\n",
       " 'संकलन',\n",
       " '*',\n",
       " 'भइरहेको',\n",
       " '*',\n",
       " 'छ',\n",
       " '*',\n",
       " '।',\n",
       " '*',\n",
       " 'तर',\n",
       " '*',\n",
       " '?',\n",
       " '*',\n",
       " 'यो',\n",
       " '*',\n",
       " 'सबै',\n",
       " '*',\n",
       " 'कुरा',\n",
       " '*',\n",
       " 'अहिले',\n",
       " '*',\n",
       " '<unk>',\n",
       " '*',\n",
       " 'जस्तो',\n",
       " '*',\n",
       " 'लागेको',\n",
       " '*',\n",
       " 'छ',\n",
       " '*',\n",
       " '।',\n",
       " '*',\n",
       " 'हाम्रो',\n",
       " '*',\n",
       " '<unk>',\n",
       " '*',\n",
       " 'धेरै',\n",
       " '*',\n",
       " 'कुरा',\n",
       " '*',\n",
       " 'बुझेको',\n",
       " '*',\n",
       " 'छैन',\n",
       " '*',\n",
       " 'तर',\n",
       " '*',\n",
       " 'त्यो',\n",
       " '*',\n",
       " 'थाहा']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e3f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
