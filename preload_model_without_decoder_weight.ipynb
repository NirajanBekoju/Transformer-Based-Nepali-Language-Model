{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38fe5122-de9c-45d0-a441-ea8f44a6d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import regex as re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from model import TransformerModel\n",
    "from utils import preProcessText, getTokenizer\n",
    "from config import getConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2524d9-beb4-429f-96de-07504f8ecc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_config, ntokens):\n",
    "    emsize = model_config[\"emsize\"]\n",
    "    d_hid = model_config[\"d_hid\"]\n",
    "    nlayers = model_config[\"nlayers\"]\n",
    "    nhead = model_config[\"nhead\"]\n",
    "    dropout = model_config[\"dropout\"]\n",
    "    model = TransformerModel(ntokens, emsize,nhead, d_hid, nlayers, dropout)\n",
    "    return model\n",
    "\n",
    "def loadModelExceptDecoderWeight(model, best_model_path):\n",
    "    if os.path.exists(best_model_path):\n",
    "        model_state_dict = model.state_dict()\n",
    "        \n",
    "        print(f\"Preloading model {best_model_path}\")\n",
    "        state = torch.load(best_model_path)\n",
    "        pretrained_state_dict = state['model_state_dict']\n",
    "        pretrained_state_dict = {k: v for k, v in pretrained_state_dict.items() if 'decoder' not in k}\n",
    "\n",
    "        model_state_dict.update(pretrained_state_dict)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "        for param in model.decoder.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        return model\n",
    "    else:\n",
    "        raise Exception(\"Model Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24584a2b-0127-4644-9e35-7b46b2fc3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emsize': 300, 'd_hid': 1024, 'nlayers': 4, 'nhead': 4, 'dropout': 0.2, 'bptt': 64}\n",
      "{'logs': 'tensorboard_logs', 'epochs': 25}\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niranjan/miniconda3/envs/cslr/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model_config, app_config = getConfig()\n",
    "print(model_config)\n",
    "print(app_config)\n",
    "\n",
    "bptt=model_config[\"bptt\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "softmax = nn.Softmax(dim=2)\n",
    "\n",
    "tokenizer, vocab = getTokenizer()\n",
    "ntokens = len(vocab)\n",
    "model = get_model(model_config, ntokens).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226cab85-18c3-4693-9295-88212a8fcb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=300, bias=True)\n",
      "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embedding): Embedding(60507, 300)\n",
      "  (decoder): Linear(in_features=300, out_features=60507, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b367c408-d574-4795-b777-0f3479388e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading model models/best_model_sample_test_corrected.pt\n",
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=300, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=300, bias=True)\n",
      "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embedding): Embedding(60507, 300)\n",
      "  (decoder): Linear(in_features=300, out_features=60507, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'models/best_model_sample_test_corrected.pt'\n",
    "loaded_model = loadModelExceptDecoderWeight(model, best_model_path)\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcc90c-b1cf-48cf-954b-6fa5f1f84f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cslr",
   "language": "python",
   "name": "cslr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
