{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8527adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "import regex as re\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e220a3-c158-473f-9493-a7cd7b97042b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aeb8065-de42-4345-bb31-dfbad27c3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "। ? , ऀ ॿ †\n"
     ]
    }
   ],
   "source": [
    "print(\"\\u0964\", \"\\u003f\", \"\\u002c\", \"\\u0900\", \"\\u097F\", \"\\u2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18adf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  : ./modified_ne_dedup.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = './modified_ne_dedup.txt'\n",
    "if not os.path.exists(file_path):\n",
    "    with open('./ne_dedup.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        # put space in beteen the | -> devanagari danda to make it a separate word.\n",
    "        text = re.sub(r'\\s*[\\u0964]\\s*', r'\\u0020\\u0964\\u0020', text)\n",
    "        # put space around the question mark ?  to make it a separate word\n",
    "        text = re.sub(r'\\s*[\\u003f]\\s*', r'\\u0020\\u003f\\u0020', text)\n",
    "        # put space in between comma(,)\n",
    "        text = re.sub(r'\\s*[\\u002c]\\s*', r'\\u0020\\u002c\\u0020', text)\n",
    "        # remove space around the new line character\n",
    "        text = re.sub(r'\\s*\\n\\s*','\\n', text)\n",
    "        # replace any non-devangari string with a blank\n",
    "        text = re.sub(r'[^\\u0900-\\u097F,?\\s+]','', text) \n",
    "    with open('./modified_ne_dedup.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "else:\n",
    "    print(f\"Reading file  : {file_path}\")\n",
    "    with open('./modified_ne_dedup.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cda573-4fb0-4593-ae9d-e6a80f5d1f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341961"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b4a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 30000\n",
    "test_data_length = 10000\n",
    "\n",
    "train_iter_first = text.split('\\n')[:train_split]\n",
    "test_iter = text.split('\\n')[train_split:train_split+test_data_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d594a78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_iter_first), type(train_iter_first[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ee116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(None)\n",
    "vocab = build_vocab_from_iterator(\n",
    "    map(tokenizer, train_iter_first), specials=['<unk>']\n",
    "        )\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4a18e0c-e200-4d65-b294-5d17a7d96276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "९९१६५: 342568\n",
      "९८७०: 342566\n"
     ]
    }
   ],
   "source": [
    "type(vocab.vocab.get_stoi())\n",
    "for key, value in list(vocab.vocab.get_stoi().items())[:2]:\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32332624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    # obtain the data in tensor format for each line\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long)\n",
    "            for item in raw_text_iter]\n",
    "    # concatenate all the lines\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8213163c-3bc9-4f75-ab56-f9461658442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    भित्रको कामको जानकारी को पार्ट टाइम छोटो समयको बिहान पार्ट टाइम लामो समयको पार्ट टाइमको जानकारी\n",
      "['भित्रको', 'कामको', 'जानकारी', 'को', 'पार्ट', 'टाइम', 'छोटो', 'समयको', 'बिहान', 'पार्ट', 'टाइम', 'लामो', 'समयको', 'पार्ट', 'टाइमको', 'जानकारी']\n",
      "[5282, 1266, 66, 32, 22985, 6753, 1678, 1818, 398, 22985, 6753, 252, 1818, 22985, 52799, 66]\n"
     ]
    }
   ],
   "source": [
    "print(test_iter[0])\n",
    "print(tokenizer(test_iter[0]))\n",
    "print(vocab(tokenizer(test_iter[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14e41fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_process(train_iter_first)\n",
    "test_data = data_process(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ca4903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6406801]), torch.Size([2102501]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b8f1855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342571\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e24971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data: Tensor, batch_size: int) -> Tensor:\n",
    "    \"\"\"Divides the data into batch_size separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "    Args:\n",
    "        data: Tensor, shape [N]\n",
    "        batch_size: int, batch size\n",
    "    Returns:\n",
    "        Tensor of shape [N // bsz, bsz]\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // batch_size\n",
    "    data = data[:seq_len * batch_size]\n",
    "    data = data.view(batch_size, seq_len).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda3aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13]) tensor([ 2087,  5695,   569,   898, 28362,   358,   466,   411,  6549,   294,\n",
      "            0,   358,   466])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2087, 28362,  6549],\n",
       "        [ 5695,   358,   294],\n",
       "        [  569,   466,     0],\n",
       "        [  898,   411,   358]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['आधिकारिक निर्णयको कारणले', 'वाणिज्य बिभागले', 'संयुक्त राज्य अमेरिकी समुद्री पानी निर्माताद्वारा संयुक्त राज्य']\n",
    "sample_data = data_process(text)\n",
    "print(sample_data.size(), sample_data)\n",
    "\n",
    "sample_data = batchify(sample_data, 3)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50e04c51-1743-4d7a-bb7d-2311bd27c077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6406801])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb776cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "batched_train_data = batchify(train_data, bptt).to(device)  # shape [seq_len, batch_size]\n",
    "batched_test_data = batchify(test_data, bptt).to(device)\n",
    "\n",
    "\n",
    "import math\n",
    "def get_batch(source: Tensor, i: int):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    #target = source[i+1:i+1+seq_len]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6290c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2)\n",
    "                             * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7cfdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niranjan/miniconda3/envs/cslr/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 300  # embedding dimension\n",
    "d_hid = 400  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2 # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.05  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize,nhead, d_hid,\n",
    "                         nlayers, dropout).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52bed039",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 1  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99227194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bcf16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(batched_train_data) // bptt\n",
    "    progress_bar = tqdm(enumerate(range(0, batched_train_data.size(0) - 1, bptt)), total=num_batches, desc=f'Epoch {epoch}')\n",
    "    for batch_idx, i in progress_bar:\n",
    "        ### batch_idx -> (1, 2, 3, 4, ...)\n",
    "        ### i -> (0, bptt, 2*bptt, ....)\n",
    "        data, targets = get_batch(batched_train_data, i)\n",
    "        batch_size = data.size(0)\n",
    "        if batch_size != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:batch_size, :batch_size]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        ## calculate the postfix description for the progress bar\n",
    "        cur_loss = total_loss / (batch_idx + 1)\n",
    "        ppl = math.exp(cur_loss)\n",
    "        \n",
    "        progress_bar.set_postfix({\"loss\": cur_loss, \"ppl\" : ppl}, refresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e875bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2)\n",
    "# softmax = nn.LogSoftmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61169dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(eval_data) // bptt\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(enumerate(range(0, eval_data.size(0) - 1, bptt)), total=num_batches, desc=f'Validation {epoch}')\n",
    "        for batch_idx, i in progress_bar:\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            batch_size = data.size(0)\n",
    "            if batch_size != bptt:\n",
    "                src_mask = src_mask[:batch_size, :batch_size]\n",
    "            output = model(data, src_mask)\n",
    "            output_softmax = softmax(output)\n",
    "            output_softmax_permuted = output_softmax.permute(1, 0, 2)\n",
    "            indices = torch.argmax(output_softmax_permuted, dim=2)\n",
    "            target_indices = targets.t()\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
    "    \n",
    "    return total_loss / (len(eval_data) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f532766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎      | 209/5230 [00:42<16:51,  4.97it/s, loss=10.4, ppl=3.43e+4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     17\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     eval_loss \u001b[38;5;241m=\u001b[39m evaluate(model, batched_test_data)\n\u001b[1;32m     20\u001b[0m     eval_ppl \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(eval_loss)\n",
      "Cell \u001b[0;32mIn[24], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     20\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 23\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m## calculate the postfix description for the progress bar\u001b[39;00m\n\u001b[1;32m     26\u001b[0m cur_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop over epochs. Save the model if the validation loss is the best\n",
    "# we've seen so far. Adjust the learning rate after each epoch.\n",
    "import copy\n",
    "best_val_loss = float('inf')\n",
    "epochs = 10\n",
    "best_model = None\n",
    "print(len(vocab.get_stoi()))\n",
    "\n",
    "# preload the model if exists to train more epochs\n",
    "best_model_path = 'models/best_model_sample_test_corrected.pt'\n",
    "if os.path.exists(best_model_path):\n",
    "    print(f\"loading the model {best_model_path}\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    eval_loss = evaluate(model, batched_test_data)\n",
    "    eval_ppl = math.exp(eval_loss)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "         f'valid loss {eval_loss:5.2f} | valid ppl {eval_ppl:8.2f}')\n",
    "    print('-' * 89)\n",
    "    #best_model = copy.deepcopy(model)\n",
    "    if eval_loss < best_val_loss:\n",
    "       best_val_loss = eval_loss\n",
    "       best_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67b9da-376b-446e-ab62-997bb97a2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'models'\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "torch.save(best_model.state_dict(), os.path.join(directory_path, 'best_model_sample_test_corrected.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fba88-d34b-4a19-8512-010c099bb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generator(model: nn.Module, gen_data: Tensor, no_words = 10):\n",
    "    model.eval()\n",
    "    temp_text = text\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    pred_text = []\n",
    "    for i in range(no_words):\n",
    "        print('i:', i)\n",
    "        batch_size = gen_data.size(0)\n",
    "        if batch_size != bptt:\n",
    "            src_mask_ = src_mask[:batch_size, :batch_size]\n",
    "        output_softmax = model(gen_data, src_mask_)\n",
    "        output_softmax_permuted = output_softmax.permute(1, 0, 2)\n",
    "        #print(softmax(output_softmax_permuted))\n",
    "        indices = torch.topk(output_softmax_permuted,10 ,dim=2).indices.squeeze(0)\n",
    "        values = torch.topk(softmax(output_softmax_permuted),10 ,dim=2).values\n",
    "        values = values/torch.sum(values,dim = 2,keepdims = True)\n",
    "        #print(output_softmax_permuted[indices])\n",
    "        # print(indices,values)\n",
    "        ind_sampled = torch.distributions.Categorical(values.squeeze(0)).sample()\n",
    "#         index = indices.squeeze(0)[ind_sampled.unsqueeze(0)]\n",
    "        # print('is',ind_sampled)\n",
    "        next_index = indices[-1][ind_sampled[-1]]\n",
    "        # print(indices[-1][ind_sampled[-1]])\n",
    "        \n",
    "#     return indices\n",
    "        \n",
    "        #print(indices[0],indices[1])\n",
    "        #for j in range(batch_size):\n",
    "        \n",
    "        print('next word: ', [vocab.lookup_token(next_index)],'values: ',values.squeeze(0)[-1])\n",
    "                                  \n",
    "#         print(i,\"Gen_data: \",gen_data,\"Pred_data: \",indices)\n",
    "\n",
    "\n",
    "        pred_text.append([vocab.lookup_token((next_index))][0])\n",
    "        if(batch_size <= 10):\n",
    "            gen_data = torch.cat((gen_data[:,:],next_index.unsqueeze(0).unsqueeze(0)),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "        else:\n",
    "            gen_data = torch.cat((gen_data[1:,:],next_index.unsqueeze(0).unsqueeze(0)),0)\n",
    "            batch_size= gen_data.size(0)\n",
    "            \n",
    "    return pred_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load saved model\n",
    "#model.load_state_dict(torch.load('models/best_model_3prex1005.pt'))\n",
    "model.load_state_dict(torch.load('models/best_model_sample_test_corrected.pt'))\n",
    "model.to(device)\n",
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "491e7160-5fde-4975-80b4-39a5d026e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) tensor([68, 53,  0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[68, 53,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['आधिकारिक निर्णयको कारणले', 'वाणिज्य बिभागले', 'संयुक्त राज्य अमेरिकी समुद्री पानी निर्माताद्वारा संयुक्त राज्य']\n",
    "text = ['यो सकियो। म काठमाडौं घुम्दै छु']\n",
    "text = ['म काठमाडौं घुम्दै']\n",
    "sample_data = data_process(text)\n",
    "print(sample_data.size(), sample_data)\n",
    "\n",
    "sample_data = batchify(sample_data, 3)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bf265b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "next word:  ['गाउँपालिका'] values:  tensor([0.2206, 0.1376, 0.1331, 0.1140, 0.1128, 0.1114, 0.0491, 0.0444, 0.0400,\n",
      "        0.0370], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 1\n",
      "next word:  ['३'] values:  tensor([0.2736, 0.2708, 0.1952, 0.0521, 0.0502, 0.0492, 0.0366, 0.0311, 0.0275,\n",
      "        0.0137], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 2\n",
      "next word:  ['मा'] values:  tensor([0.2808, 0.2520, 0.1427, 0.0669, 0.0667, 0.0568, 0.0361, 0.0356, 0.0355,\n",
      "        0.0271], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 3\n",
      "next word:  ['भएको'] values:  tensor([0.4773, 0.1172, 0.0760, 0.0676, 0.0570, 0.0497, 0.0441, 0.0374, 0.0372,\n",
      "        0.0365], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 4\n",
      "next word:  ['हो'] values:  tensor([0.5777, 0.1994, 0.0839, 0.0303, 0.0251, 0.0250, 0.0213, 0.0133, 0.0124,\n",
      "        0.0117], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 5\n",
      "next word:  ['।'] values:  tensor([0.8751, 0.0477, 0.0418, 0.0124, 0.0070, 0.0051, 0.0032, 0.0028, 0.0027,\n",
      "        0.0022], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 6\n",
      "next word:  ['कार्तिक'] values:  tensor([0.2386, 0.1144, 0.1030, 0.1029, 0.0885, 0.0883, 0.0766, 0.0664, 0.0644,\n",
      "        0.0569], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 7\n",
      "next word:  ['२७'] values:  tensor([0.3102, 0.2171, 0.1623, 0.1172, 0.0703, 0.0370, 0.0256, 0.0236, 0.0188,\n",
      "        0.0180], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 8\n",
      "next word:  [','] values:  tensor([0.3880, 0.1841, 0.1474, 0.1172, 0.0485, 0.0297, 0.0259, 0.0220, 0.0187,\n",
      "        0.0185], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 9\n",
      "next word:  ['२०७५'] values:  tensor([0.8166, 0.0689, 0.0444, 0.0237, 0.0100, 0.0082, 0.0076, 0.0071, 0.0070,\n",
      "        0.0065], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 10\n",
      "next word:  ['।'] values:  tensor([0.3788, 0.2581, 0.1168, 0.1147, 0.0399, 0.0260, 0.0221, 0.0160, 0.0141,\n",
      "        0.0134], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 11\n",
      "next word:  ['काठमाडौं'] values:  tensor([0.2799, 0.1844, 0.0852, 0.0783, 0.0667, 0.0664, 0.0638, 0.0623, 0.0564,\n",
      "        0.0564], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 12\n",
      "next word:  ['।'] values:  tensor([0.4062, 0.3313, 0.0546, 0.0495, 0.0485, 0.0253, 0.0245, 0.0241, 0.0206,\n",
      "        0.0154], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 13\n",
      "next word:  ['सो'] values:  tensor([0.4056, 0.0972, 0.0854, 0.0741, 0.0740, 0.0712, 0.0554, 0.0483, 0.0457,\n",
      "        0.0431], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 14\n",
      "next word:  ['क्षेत्रमा'] values:  tensor([0.4531, 0.2751, 0.0786, 0.0388, 0.0353, 0.0301, 0.0236, 0.0235, 0.0211,\n",
      "        0.0208], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 15\n",
      "next word:  ['ठूलो'] values:  tensor([0.3757, 0.0937, 0.0842, 0.0800, 0.0763, 0.0712, 0.0697, 0.0526, 0.0512,\n",
      "        0.0453], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 16\n",
      "next word:  ['रहेको'] values:  tensor([0.2454, 0.1522, 0.0969, 0.0932, 0.0907, 0.0846, 0.0679, 0.0629, 0.0548,\n",
      "        0.0515], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 17\n",
      "next word:  ['छ'] values:  tensor([0.4387, 0.1823, 0.0580, 0.0570, 0.0556, 0.0552, 0.0428, 0.0402, 0.0376,\n",
      "        0.0325], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 18\n",
      "next word:  [','] values:  tensor([0.6324, 0.1945, 0.1418, 0.0131, 0.0043, 0.0037, 0.0033, 0.0033, 0.0021,\n",
      "        0.0015], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 19\n",
      "next word:  ['नेपाल'] values:  tensor([0.3506, 0.2139, 0.0879, 0.0641, 0.0524, 0.0514, 0.0496, 0.0495, 0.0445,\n",
      "        0.0362], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 20\n",
      "next word:  ['र'] values:  tensor([0.2663, 0.2007, 0.0994, 0.0771, 0.0721, 0.0673, 0.0648, 0.0608, 0.0498,\n",
      "        0.0418], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 21\n",
      "next word:  ['भारतीय'] values:  tensor([0.1373, 0.1256, 0.1182, 0.1172, 0.0944, 0.0925, 0.0839, 0.0839, 0.0753,\n",
      "        0.0716], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 22\n",
      "next word:  ['नेपाल'] values:  tensor([0.4081, 0.3231, 0.1013, 0.0354, 0.0255, 0.0250, 0.0209, 0.0206, 0.0202,\n",
      "        0.0198], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 23\n",
      "next word:  ['र'] values:  tensor([0.2851, 0.1374, 0.1227, 0.1162, 0.0694, 0.0617, 0.0558, 0.0557, 0.0495,\n",
      "        0.0466], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 24\n",
      "next word:  ['राष्ट्रिय'] values:  tensor([0.1481, 0.1354, 0.1159, 0.1088, 0.0945, 0.0923, 0.0914, 0.0841, 0.0663,\n",
      "        0.0633], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 25\n",
      "next word:  ['निकुञ्ज'] values:  tensor([0.5423, 0.2323, 0.0406, 0.0394, 0.0318, 0.0248, 0.0248, 0.0245, 0.0207,\n",
      "        0.0189], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 26\n",
      "next word:  [','] values:  tensor([0.4060, 0.3497, 0.1442, 0.0364, 0.0122, 0.0112, 0.0111, 0.0103, 0.0098,\n",
      "        0.0090], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 27\n",
      "next word:  ['आर्थिक'] values:  tensor([0.2712, 0.1524, 0.0994, 0.0884, 0.0793, 0.0745, 0.0657, 0.0618, 0.0575,\n",
      "        0.0499], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 28\n",
      "next word:  [','] values:  tensor([0.1973, 0.1918, 0.1398, 0.1021, 0.0871, 0.0730, 0.0596, 0.0582, 0.0484,\n",
      "        0.0427], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 29\n",
      "next word:  ['आर्थिक'] values:  tensor([0.1881, 0.1428, 0.1426, 0.1157, 0.1028, 0.0941, 0.0663, 0.0532, 0.0511,\n",
      "        0.0432], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 30\n",
      "next word:  ['वर्षमा'] values:  tensor([0.2955, 0.1295, 0.1282, 0.1067, 0.0921, 0.0675, 0.0617, 0.0447, 0.0371,\n",
      "        0.0371], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 31\n",
      "next word:  ['१०'] values:  tensor([0.3864, 0.1777, 0.1123, 0.0746, 0.0479, 0.0466, 0.0426, 0.0391, 0.0382,\n",
      "        0.0347], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 32\n",
      "next word:  [','] values:  tensor([0.2615, 0.1795, 0.1105, 0.0992, 0.0837, 0.0675, 0.0595, 0.0532, 0.0436,\n",
      "        0.0420], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 33\n",
      "next word:  ['२'] values:  tensor([0.2962, 0.1952, 0.0903, 0.0879, 0.0608, 0.0607, 0.0536, 0.0535, 0.0517,\n",
      "        0.0501], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 34\n",
      "next word:  ['को'] values:  tensor([0.2715, 0.2570, 0.1390, 0.1179, 0.0650, 0.0353, 0.0329, 0.0297, 0.0282,\n",
      "        0.0234], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 35\n",
      "next word:  ['लागि'] values:  tensor([0.2779, 0.1658, 0.1426, 0.1062, 0.0608, 0.0568, 0.0567, 0.0529, 0.0405,\n",
      "        0.0399], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 36\n",
      "next word:  ['तीन'] values:  tensor([0.1520, 0.1205, 0.1198, 0.1061, 0.0985, 0.0954, 0.0903, 0.0749, 0.0741,\n",
      "        0.0683], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 37\n",
      "next word:  ['दिन'] values:  tensor([0.1726, 0.1573, 0.1251, 0.1235, 0.0991, 0.0861, 0.0684, 0.0617, 0.0545,\n",
      "        0.0517], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 38\n",
      "next word:  ['आज'] values:  tensor([0.2277, 0.1984, 0.1243, 0.1145, 0.0718, 0.0626, 0.0580, 0.0498, 0.0484,\n",
      "        0.0446], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 39\n",
      "next word:  ['१०'] values:  tensor([0.2389, 0.1911, 0.0965, 0.0920, 0.0906, 0.0805, 0.0561, 0.0550, 0.0546,\n",
      "        0.0448], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 40\n",
      "next word:  ['हजार'] values:  tensor([0.2423, 0.1522, 0.1048, 0.1034, 0.0878, 0.0786, 0.0679, 0.0576, 0.0557,\n",
      "        0.0497], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 41\n",
      "next word:  ['३'] values:  tensor([0.2405, 0.1742, 0.1448, 0.0893, 0.0786, 0.0600, 0.0573, 0.0549, 0.0502,\n",
      "        0.0501], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 42\n",
      "next word:  ['सय'] values:  tensor([0.8623, 0.0486, 0.0324, 0.0211, 0.0076, 0.0075, 0.0067, 0.0058, 0.0043,\n",
      "        0.0038], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 43\n",
      "next word:  ['दिनमा'] values:  tensor([0.2621, 0.1595, 0.1477, 0.0813, 0.0712, 0.0613, 0.0605, 0.0604, 0.0503,\n",
      "        0.0458], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 44\n",
      "next word:  ['१'] values:  tensor([0.1864, 0.1479, 0.1431, 0.1022, 0.0878, 0.0763, 0.0755, 0.0613, 0.0607,\n",
      "        0.0587], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 45\n",
      "next word:  ['सय'] values:  tensor([0.6936, 0.0850, 0.0804, 0.0555, 0.0438, 0.0142, 0.0079, 0.0069, 0.0066,\n",
      "        0.0060], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 46\n",
      "next word:  ['करोड'] values:  tensor([0.1912, 0.1583, 0.1201, 0.0888, 0.0853, 0.0835, 0.0760, 0.0707, 0.0703,\n",
      "        0.0559], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 47\n",
      "next word:  ['४'] values:  tensor([0.1670, 0.1663, 0.1543, 0.1050, 0.0836, 0.0728, 0.0723, 0.0596, 0.0596,\n",
      "        0.0596], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 48\n",
      "next word:  ['लाख'] values:  tensor([0.4642, 0.1689, 0.1105, 0.0923, 0.0438, 0.0329, 0.0285, 0.0259, 0.0190,\n",
      "        0.0139], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 49\n",
      "next word:  ['पर्यटक'] values:  tensor([0.3022, 0.1731, 0.0992, 0.0959, 0.0648, 0.0634, 0.0559, 0.0502, 0.0479,\n",
      "        0.0474], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print(sample_data[:,-1].unsqueeze(1))\n",
    "# print(sample_data)\n",
    "z = generator(best_model, sample_data[:,-1].unsqueeze(1),no_words = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5b07c9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'म काठमाडौं घुम्दैगाउँपालिका ३ मा भएको हो । कार्तिक २७ , २०७५ । काठमाडौं । सो क्षेत्रमा ठूलो रहेको छ , नेपाल र भारतीय नेपाल र राष्ट्रिय निकुञ्ज , आर्थिक , आर्थिक वर्षमा १० , २ को लागि तीन दिन आज १० हजार ३ सय दिनमा १ सय करोड ४ लाख पर्यटक'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0] +' '.join(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d23f62b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.053659439086914"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(best_model, sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "343b249f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nआधिकारिक निर्णयको कारणले , वाणिज्य बिभागले , \\nसंयुक्त राज्य अमेरिकी समुद्री पानी निर्माताद्वारा संयुक्त\\n\\nविकास गर्न प्रोत्साहित गरी सहकारी क्षेत्रले आर्थिक दृष्टिले सक्रिय\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "आधिकारिक निर्णयको कारणले , वाणिज्य बिभागले , \n",
    "संयुक्त राज्य अमेरिकी समुद्री पानी निर्माताद्वारा संयुक्त\n",
    "\n",
    "विकास गर्न प्रोत्साहित गरी सहकारी क्षेत्रले आर्थिक दृष्टिले सक्रिय\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54a8d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ['गर्ने']\n",
    "st_i = data_process(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "121a3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_i = st_i.unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ba838ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "next word:  ['तयारी'] values:  tensor([0.2037, 0.1642, 0.1544, 0.0870, 0.0816, 0.0761, 0.0721, 0.0630, 0.0538,\n",
      "        0.0439], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 1\n",
      "next word:  ['गरेको'] values:  tensor([0.7071, 0.0723, 0.0510, 0.0422, 0.0361, 0.0231, 0.0203, 0.0192, 0.0168,\n",
      "        0.0120], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 2\n",
      "next word:  ['छ'] values:  tensor([0.7326, 0.1537, 0.0495, 0.0210, 0.0087, 0.0082, 0.0074, 0.0071, 0.0060,\n",
      "        0.0056], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 3\n",
      "next word:  ['।'] values:  tensor([9.2223e-01, 4.0236e-02, 2.5793e-02, 4.5705e-03, 2.0539e-03, 1.4398e-03,\n",
      "        9.9501e-04, 9.9269e-04, 8.5499e-04, 8.3322e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "i: 4\n",
      "next word:  ['यस'] values:  tensor([0.2811, 0.1637, 0.1249, 0.1007, 0.0757, 0.0526, 0.0514, 0.0512, 0.0496,\n",
      "        0.0491], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 5\n",
      "next word:  ['पटक'] values:  tensor([0.4641, 0.1059, 0.0876, 0.0739, 0.0737, 0.0641, 0.0607, 0.0296, 0.0205,\n",
      "        0.0199], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 6\n",
      "next word:  ['पटक'] values:  tensor([0.2635, 0.2388, 0.1053, 0.0979, 0.0778, 0.0516, 0.0490, 0.0430, 0.0371,\n",
      "        0.0359], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 7\n",
      "next word:  ['पटक'] values:  tensor([0.2208, 0.2081, 0.0986, 0.0985, 0.0868, 0.0681, 0.0676, 0.0544, 0.0506,\n",
      "        0.0465], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 8\n",
      "next word:  [','] values:  tensor([0.2202, 0.1473, 0.1461, 0.0908, 0.0893, 0.0731, 0.0591, 0.0588, 0.0579,\n",
      "        0.0572], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "i: 9\n",
      "next word:  ['रौतहट'] values:  tensor([0.1517, 0.1435, 0.1125, 0.1044, 0.0912, 0.0911, 0.0879, 0.0821, 0.0735,\n",
      "        0.0621], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z_ = generator(best_model, st_i,no_words =10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58e18f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तयारी गरेको छ । यस पटक पटक पटक , रौतहट'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b59c4eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['तयारी', 'गरेको', 'छ', '।', 'यस', 'पटक', 'पटक', 'पटक', ',', 'रौतहट']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf9203b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नेपाल'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_itos()[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece4bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cslr",
   "language": "python",
   "name": "cslr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
